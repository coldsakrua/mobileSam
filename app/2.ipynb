{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_5m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "../mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_11m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "../mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "../mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_384 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "../mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_512 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import ImageDraw\n",
    "from utils.tools import box_prompt, format_results, point_prompt\n",
    "from utils.tools_gradio import fast_process\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from mobile_sam import SamAutomaticMaskGenerator, SamPredictor, sam_model_registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained model\n",
    "sam_checkpoint = \"../weights/mobile_sam.pt\"\n",
    "model_type = \"vit_t\"\n",
    "\n",
    "mobile_sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "mobile_sam = mobile_sam.to(device=device)\n",
    "mobile_sam.eval()\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(mobile_sam)\n",
    "predictor = SamPredictor(mobile_sam)\n",
    "\n",
    "# Description\n",
    "title = \"<center><strong><font size='8'>Faster Segment Anything(MobileSAM)<font></strong></center>\"\n",
    "\n",
    "description_e = \"\"\"This is a demo of [Faster Segment Anything(MobileSAM) Model](https://github.com/ChaoningZhang/MobileSAM).\n",
    "\n",
    "                   We will provide box mode soon. \n",
    "\n",
    "                   Enjoy!\n",
    "                \n",
    "              \"\"\"\n",
    "\n",
    "description_p = \"\"\" # Instructions for point mode\n",
    "\n",
    "                0. Restart by click the Restart button\n",
    "                1. Select a point with Add Mask for the foreground (Must)\n",
    "                2. Select a point with Remove Area for the background (Optional)\n",
    "                3. Click the Start Segmenting.\n",
    "\n",
    "              \"\"\"\n",
    "\n",
    "examples = [\n",
    "    [\"assets/picture3.jpg\"],\n",
    "    [\"assets/picture4.jpg\"],\n",
    "    [\"assets/picture5.jpg\"],\n",
    "    [\"assets/picture6.jpg\"],\n",
    "    [\"assets/picture1.jpg\"],\n",
    "    [\"assets/picture2.jpg\"],\n",
    "]\n",
    "\n",
    "default_example = examples[0]\n",
    "\n",
    "css = \"h1 { text-align: center } .about { text-align: justify; padding-left: 10%; padding-right: 10%; }\"\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def segment_everything(\n",
    "    image,\n",
    "    input_size=1024,\n",
    "    better_quality=False,\n",
    "    withContours=True,\n",
    "    use_retina=True,\n",
    "    mask_random_color=True,\n",
    "):\n",
    "    global mask_generator\n",
    "\n",
    "    input_size = int(input_size)\n",
    "    w, h = image.size\n",
    "    scale = input_size / max(w, h)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "    image = image.resize((new_w, new_h))\n",
    "\n",
    "    nd_image = np.array(image)\n",
    "    annotations = mask_generator.generate(nd_image)\n",
    "\n",
    "    fig = fast_process(\n",
    "        annotations=annotations,\n",
    "        image=image,\n",
    "        device=device,\n",
    "        scale=(1024 // input_size),\n",
    "        better_quality=better_quality,\n",
    "        mask_random_color=mask_random_color,\n",
    "        bbox=None,\n",
    "        use_retina=use_retina,\n",
    "        withContours=withContours,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def segment_with_points(\n",
    "    image,\n",
    "    input_size=1024,\n",
    "    better_quality=False,\n",
    "    withContours=True,\n",
    "    use_retina=True,\n",
    "    mask_random_color=True,\n",
    "):\n",
    "    global global_points\n",
    "    global global_point_label\n",
    "\n",
    "    input_size = int(input_size)\n",
    "    w, h = image.size\n",
    "    scale = input_size / max(w, h)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "    image = image.resize((new_w, new_h))\n",
    "\n",
    "    scaled_points = np.array(\n",
    "        [[int(x * scale) for x in point] for point in global_points]\n",
    "    )\n",
    "    scaled_point_label = np.array(global_point_label)\n",
    "\n",
    "    if scaled_points.size == 0 and scaled_point_label.size == 0:\n",
    "        print(\"No points selected\")\n",
    "        return image, image\n",
    "\n",
    "    print(scaled_points, scaled_points is not None)\n",
    "    print(scaled_point_label, scaled_point_label is not None)\n",
    "\n",
    "    nd_image = np.array(image)\n",
    "    predictor.set_image(nd_image)\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=scaled_points,\n",
    "        point_labels=scaled_point_label,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "\n",
    "    results = format_results(masks, scores, logits, 0)\n",
    "\n",
    "    annotations, _ = point_prompt(\n",
    "        results, scaled_points, scaled_point_label, new_h, new_w\n",
    "    )\n",
    "    annotations = np.array([annotations])\n",
    "\n",
    "    fig = fast_process(\n",
    "        annotations=annotations,\n",
    "        image=image,\n",
    "        device=device,\n",
    "        scale=(1024 // input_size),\n",
    "        better_quality=better_quality,\n",
    "        mask_random_color=mask_random_color,\n",
    "        bbox=None,\n",
    "        use_retina=use_retina,\n",
    "        withContours=withContours,\n",
    "    )\n",
    "\n",
    "    global_points = []\n",
    "    global_point_label = []\n",
    "    # return fig, None\n",
    "    return fig, image\n",
    "\n",
    "\n",
    "def get_points_with_draw(image, label, evt: gr.SelectData):\n",
    "    global global_points\n",
    "    global global_point_label\n",
    "\n",
    "    x, y = evt.index[0], evt.index[1]\n",
    "    point_radius, point_color = 15, (255, 255, 0) if label == \"Add Mask\" else (\n",
    "        255,\n",
    "        0,\n",
    "        255,\n",
    "    )\n",
    "    global_points.append([x, y])\n",
    "    global_point_label.append(1 if label == \"Add Mask\" else 0)\n",
    "\n",
    "    print(x, y, label == \"Add Mask\")\n",
    "\n",
    "    # 创建一个可以在图像上绘图的对象\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.ellipse(\n",
    "        [(x - point_radius, y - point_radius), (x + point_radius, y + point_radius)],\n",
    "        fill=point_color,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "cond_img_e = gr.Image(label=\"Input\", value=default_example[0], type=\"pil\")\n",
    "cond_img_p = gr.Image(label=\"Input with points\", value=default_example[0], type=\"pil\")\n",
    "\n",
    "segm_img_e = gr.Image(label=\"Segmented Image\", interactive=False, type=\"pil\")\n",
    "segm_img_p = gr.Image(\n",
    "    label=\"Segmented Image with points\", interactive=False, type=\"pil\"\n",
    ")\n",
    "\n",
    "global_points = []\n",
    "global_point_label = []\n",
    "\n",
    "input_size_slider = gr.components.Slider(\n",
    "    minimum=512,\n",
    "    maximum=1024,\n",
    "    value=1024,\n",
    "    step=64,\n",
    "    label=\"Input_size\",\n",
    "    info=\"Our model was trained on a size of 1024\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(css=css, title=\"Faster Segment Anything(MobileSAM)\") as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            # Title\n",
    "            gr.Markdown(title)\n",
    "\n",
    "    with gr.Tab(\"Point mode\"):\n",
    "        # Images\n",
    "        with gr.Row(variant=\"panel\"):\n",
    "            with gr.Column(scale=1):\n",
    "                cond_img_p.render()\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                segm_img_p.render()\n",
    "\n",
    "        # Submit & Clear\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                with gr.Row():\n",
    "                    add_or_remove = gr.Radio(\n",
    "                        [\"Add Mask\", \"Remove Area\"],\n",
    "                        value=\"Add Mask\",\n",
    "                    )\n",
    "\n",
    "                    with gr.Column():\n",
    "                        segment_btn_p = gr.Button(\n",
    "                            \"Start segmenting!\", variant=\"primary\"\n",
    "                        )\n",
    "                        clear_btn_p = gr.Button(\"Restart\", variant=\"secondary\")\n",
    "\n",
    "                gr.Markdown(\"Try some of the examples below ⬇️\")\n",
    "                gr.Examples(\n",
    "                    examples=examples,\n",
    "                    inputs=[cond_img_p],\n",
    "                    # outputs=segm_img_p,\n",
    "                    # fn=segment_with_points,\n",
    "                    # cache_examples=True,\n",
    "                    examples_per_page=4,\n",
    "                )\n",
    "\n",
    "            with gr.Column():\n",
    "                # Description\n",
    "                gr.Markdown(description_p)\n",
    "\n",
    "    cond_img_p.select(get_points_with_draw, [cond_img_p, add_or_remove], cond_img_p)\n",
    "\n",
    "    # segment_btn_e.click(\n",
    "    #     segment_everything,\n",
    "    #     inputs=[\n",
    "    #         cond_img_e,\n",
    "    #         input_size_slider,\n",
    "    #         mor_check,\n",
    "    #         contour_check,\n",
    "    #         retina_check,\n",
    "    #     ],\n",
    "    #     outputs=segm_img_e,\n",
    "    # )\n",
    "\n",
    "    segment_btn_p.click(\n",
    "        segment_with_points, inputs=[cond_img_p], outputs=[segm_img_p, cond_img_p]\n",
    "    )\n",
    "\n",
    "    def clear():\n",
    "        return None, None\n",
    "\n",
    "    def clear_text():\n",
    "        return None, None, None\n",
    "\n",
    "    # clear_btn_e.click(clear, outputs=[cond_img_e, segm_img_e])\n",
    "    clear_btn_p.click(clear, outputs=[cond_img_p, segm_img_p])\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
